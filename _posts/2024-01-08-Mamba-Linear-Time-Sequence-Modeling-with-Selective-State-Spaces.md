---
layout: post
title:  "[PAPER] Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
author: jaealways
categories: [ paper, NLP]
tags: [PAPER, ICLR'24, LLM, State Space]
---


# [PAPER] Mamba: Linear-Time Sequence Modeling with Selective State Spaces


[reference: Albert Gu et al, "Mamba: Linear-Time Sequence Modeling with Selective State Spaces", 2023](https://arxiv.org/ftp/arxiv/papers/2312/2312.00752.pdf)


# Abstract

- **딥러닝의 기반 모델**: 딥러닝의 많은 응용 프로그램을 지원하는 기반 모델에서 트랜스포머 아키텍처가 널리 사용되고 있음을 설명합니다.
- **비효율성 해결**: 긴 시퀀스로 트랜스포머의 비효율성을 해결하기 위해 개발된 선형 주의, 게이트 컨볼루션, 순환 모델 및 구조화된 상태 공간 모델(SSM)과 같은 4차 시간 이하 아키텍처에 초점을 맞춘다.
- ** 선택적 상태 공간 모델(SSM)의 개선**: 입력 의존적 SSM 파라미터의 도입을 강조하여 현재 토큰을 기반으로 정보를 선택적으로 처리할 수 있는 모델의 기능을 강화한다.
- **하드웨어 인식 병렬 알고리즘**: 효율적인 컨볼루션 사용을 방해하는 변경에도 효율성을 유지하기 위해 순환 모드의 하드웨어 인식 병렬 알고리즘을 설명합니다.
- **Mamba Architecture**: 선택적 SSM을 통합하는 엔드 투 엔드 신경망 아키텍처인 Mamba를 소개하여 더 빠른 추론과 시퀀스 길이의 선형 확장을 제공합니다.
- **양식 전반의 퍼포먼스**: Mamba가 언어, 오디오, 유전체학 등 다양한 양식에서 최첨단 성능을 발휘한다고 말합니다.
- **Transformers와의 비교**: Mamba-3B 모델이 동일한 크기의 Transformers보다 성능이 뛰어나며, 사전 교육 및 다운스트림 평가 모두에서 Transformers의 두 배의 크기에 필적한다고 언급하였다.


# 1 Introduction

- **Foundation Models(FM) 및 Sequence Models**: FM은 대용량 데이터에 대해 사전 교육을 받은 후 다운스트림 작업에 맞게 조정된 대규모 모델로 자가 주의 메커니즘으로 인해 트랜스포머 모델 아키텍처를 주로 사용한다. 이 메커니즘은 컨텍스트 윈도우 내에서 정보의 조밀한 라우팅을 가능하게 하여 복잡한 데이터의 모델링을 가능하게 한다. 그러나 유한 윈도우 외부의 데이터를 모델링할 수 없고 윈도우 길이에 대한 2차 스케일링을 포함한 한계도 있다.

- **구조화된 상태 공간 시퀀스 모델(SSM)**: SSM은 시퀀스 모델링을 위한 유망한 아키텍처로 부상하고 있다. 이들은 반복 신경망(RNN), 컨볼루션 신경망(CNN) 및 고전적인 상태 공간 모델의 요소를 결합한다. SSM은 시퀀스 길이가 선형 또는 거의 선형으로 스케일링되어 시퀀스를 효율적으로 계산할 수 있으며 오디오 및 비전과 같은 연속 신호 데이터의 장거리 의존성을 모델링하는 데 효과적이었다. 그러나 텍스트와 같은 이산적이고 정보 밀도가 높은 데이터에서는 덜 효과적이다.

- **선택적 상태 공간 모델(SSM)**: 본 논문은 시퀀스 길이에서 선형 스케일링을 유지하면서 트랜스포머의 모델링 능력을 달성하는 것을 목표로 하는 새로운 클래스의 선택적 SSM을 제안한다. 이는 모델이 입력 의존적 방식으로 데이터를 효율적으로 선택할 수 있는 선택 메커니즘을 통합하여 특정 입력에 집중하거나 무시할 수 있도록 함으로써 달성된다. 이 메커니즘은 모델이 관련 없는 정보를 필터링하고 관련 정보를 무한정 유지하는 데 도움이 된다.

- **기술 혁신**: 선택적 SSM은 계산 효율성을 위해 시간과 입력이 불변해야 했던 이전 SSM의 한계를 극복하는 하드웨어 인식 알고리즘을 도입한다. 새로운 접근 방식은 컨볼루션 대신 스캔으로 반복 계산을 허용하여 GPU 메모리 계층의 IO 액세스 문제를 방지하여 보다 빠른 구현을 가능하게 한다.

- **맘바 아키텍처**: 맘바 아키텍처는 이전 SSM 아키텍처의 설계와 트랜스포머의 MLP 블록을 결합하여 단일의 균질한 설계로 이전의 심층 시퀀스 모델 아키텍처를 단순화한다. 이 아키텍처는 고품질, 빠른 훈련 및 추론 기능과 긴 컨텍스트를 효율적으로 처리할 수 있어 시퀀스에서 운영되는 일반적인 기반 모델의 백본으로 적합한 것이 특징이다.



# 2 State Space Models

"선택적 상태 공간을 사용한 맘바 선형-시간 시퀀스 모델링" 문서의 "상태 공간 모델" 섹션에서는 구조화된 상태 공간 모델(SSM) 분야의 다양한 발전과 혁신에 대해 설명합니다. 다음은 주요 사항을 요약한 것입니다:

- **S4 모델**: Gu, Goel 및 Ré(2022)와 Gu, Johnson, Goel et al.(2021)가 소개한 S4 모델은 대각선 구조와 대각선+저순위(DPLR)를 가진 구조화된 SSM을 최초로 설명했다. 그들은 연속시간 온라인 기억(HIPPO)에 연결된 DPLR SSM을 위한 효율적인 컨볼루션 알고리즘에 초점을 맞췄다.

- **DSS 모델**: Gupta, Gupta, Berant(2022)는 HIPO 초기화를 근사화함으로써 대각선 구조 SSM의 경험적 효과를 발견했으며, 이후 Gupta 등(2022)에 의해 S4D에서 이론적으로 확장되었다.

- **S5 모델**: Smith, Warrington 및 Linderman(2023)은 독립적으로 대각선 SSM 근사치를 발견했다. S5는 병렬 스캔으로 반복 계산된 최초의 S4 모델이었다. 이를 위해서는 단일 입력 단일 출력(SISO)에서 다중 입력 다중 출력(MIMO) 공식으로 전환해야 했다. 제안된 S6 모델은 S5와 스캔을 공유하지만 SISO 차원을 유지하고 하드웨어 인식 알고리즘을 사용하며 선택 메커니즘을 추가하는 데 차이가 있다.

- **Mega Model**: Ma et al. (2023)은 S4를 (복잡한 가치 대신) 실제 가치 SSM으로 단순화하는 것을 도입하여 지수 이동 평균(EMA)으로 해석했다. 또한 이들은 SSM의 이산화 단계를 EMA 감쇠 항에 연결하여 특정 맥락에서 실제 가치 SSM의 효과를 입증했다.

- **Liquid S4**: Hasani et al. (2023)은 입력 의존적 상태 전이로 S4를 증강하여 선택 메커니즘과 유사성을 공유하지만 여전히 컨벌루션적이고 선형 시간불변(LTI)에 가까운 계산을 했다.

- **기타 S4 변형**: SGConv(Y. Li et al., 2023), 하이에나(Poli et al., 2023), LongConv(Fu et al., 2023), 멀티레스Conv(J. Shi, K. A. Wang and Fox, 2023) 및 Toeplitz 신경망(Qin, Han, W. Sun, He et al., 2023)과 같은 모델은 다양한 매개변수화를 가진 S4의 컨볼루션 표현에 초점을 맞춘다. 그러나 이러한 방법은 빠른 자기회귀 추론을 용이하게 하지 않는다.

- **일반 관찰**: 위에서 언급한 SSM을 포함한 대부분의 구조화된 SSM은 비선택적이었고 일반적으로 엄격하게 선형 시간 불변(LTI)이었다.


# 3 Selective State Space Models

- ** 선택적 SSM의 역학**: 
  - 선택적 SSM은 연속적인 시간 형태로 누출 적분기로 간주될 수 있다.
  - 선택적 SSM에서 이산화 단계 크기는 학습 가능한 바이어스로 간주될 수 있는 파라미터를 포함하고, 이들은 선형 투영으로 접힌다.
  - 선택적 SSM에 대한 최종 이산 재발이 도출되며, 이는 모델이 입력에 기반하여 상태를 업데이트하는 방법을 보여준다.

- **선택적 SSM에 대한 하드웨어 인식 알고리즘**: 
  - 선택적 SSM들은 입력 의존적 선택성으로 인해 그들의 계산에서 표준 SSM들로부터 벗어난다. 고속 푸리에 변환(FFT)을 이용한 컨볼루션으로 구현될 수 있는 표준 SSM들과 달리, 선택적 SSM들은 병렬 연관 스캔을 필요로 한다.
  - 이 하드웨어 인식 알고리즘은 GPU와 같은 최신 하드웨어에서 SSM을 빠르고 메모리 효율적으로 스캔하는 데 중점을 둔다.
  - 구현은 커널 퓨전(Kernel Fusion)을 사용함으로써 메모리 IO의 양을 감소시켜, 상당한 속도 향상으로 이어진다.
  - 스캔 작업은 저속 메모리에서 고속 메모리(HBM to SRAM)로 메모리 읽기, 이산화, 병렬 연관 스캔, 출력 생성 등의 단계를 포함하여 상세하게 설명된다.
  - 이 작업은 IO를 상태 차원과 관련된 요소만큼 감소시켜 프로세스를 20-40배까지 가속화합니다.
  - 선택적 SSM 계층들의 메모리 요구사항들은 중간 상태들을 저장할 필요를 피하여 재계산 기술들에 의해 관리된다.
  - 전체 선택적 SSM 블록에 대한 메모리 요구 사항은 최적화된 트랜스포머 구현의 것과 일치하도록 최적화된다.

- **모델 성능 및 메모리 효율성**: 
  - 문서에는 서로 다른 시퀀스 길이에서 다양한 모델의 테스트 정확도를 보여주는 표가 포함되어 있어 맘바 모델의 성능을 강조한다.
  - 선택적 SSM을 사용하는 맘바 모델은 최적화된 트랜스포머 구현과 유사하게 메모리 사용에 있어서 효율적이다.

이러한 점들은 현대 컴퓨팅 하드웨어에서 효율적인 작동을 위해 선택적 SSM이 어떻게 구성되고 최적화되는지에 대한 기술적 세부사항을 보여준다.



# 4 Empirical Evaluation

문서 "선택적 상태 공간을 사용한 맘바 선형-시간 시퀀스 모델링"의 "경험적 평가 모델" 부분은 다양한 모델의 상세한 분석과 비교를 제공하지만, 다른 모델의 경험적 평가에 대한 구체적인 부분은 제공된 발췌문에서 완전히 볼 수 없는 것으로 보인다. 그러나 이용 가능한 정보를 바탕으로 다음과 같은 몇 가지 통찰을 제공한다:

- **선택적 SSM을 위한 하드웨어 인식 알고리즘**: 이 문서는 GPU와 같은 최신 하드웨어에서 선택적 SSM의 구현 세부 사항에 대해 설명한다. SSM 스캔 작업을 빠르고 메모리 효율적으로 만들기 위해 커널 융합 및 재계산 기법을 사용하는 것을 강조하며, SSM의 속도와 메모리 효율을 컨볼루션 및 주의력과 같은 다른 방법과 비교한다.

- **Model Performance Analysis**: 문서의 표는 다양한 시퀀스 길이에 걸쳐 다양한 모델의 테스트 정확도를 보여준다. 이는 맘바 모델의 성능을 여러 가지로 강조하여 다양한 시퀀스 길이를 처리하는 데 있어 효과적임을 나타낸다.

- **다양한 맥락에서 선택적 SSM **: 이 문서는 메타 강화 학습(meta-RL) 및 기타 도메인과 같은 다양한 설정에서 선택적 SSM의 적용을 탐구한다. 또한 이러한 맥락에서 선택적 메커니즘을 사용하는 것의 의미에 대해 논의한다.

- **다른 모델과의 비교**: 이 문서는 대부분의 다른 모델이 비선택적이고 일반적으로 선형 시간불변(LTI)이었다는 점에 주목하여 선택적 SSM을 다른 구조화된 SSM과 비교한다.

실증평가모형을 보다 구체적으로 요약하기 위해서는 이러한 평가가 구체적으로 논의되는 구체적인 부분에 접근할 필요가 있을 것이다. 안타깝게도 제공된 발췌문은 이 구체적인 부분 전체를 다루고 있지는 않다.


# 5 Discussion

다음은 PDF "선택적 상태 공간을 사용한 맘바 선형-시간 시퀀스 모델링"에서 나온 다섯 가지 논의를 요약한 것이다:

1. **S4 및 그 변종**:
   - S4는 사선 구조와 사선 플러스 저위 순위(DPLR)를 갖는 최초의 구조화된 상태 공간 모델(SSM)을 도입하였다.
   - 대각 구조 SSM(Diagonal Structured SSM)은 대각 SSM의 효과를 실증적으로 입증하였다.
   - S5 모델은 대각선 SSM 근사를 도입하여 병렬 스캔으로 반복 계산하였다.

2. **S4의 컨볼루션 표현**:
   - SGConv, Hyena, LongConv, MultiresConv 및 Toeplitz 신경망은 S4의 컨볼루션 표현에 초점을 맞추어 다양한 컨볼루션 커널을 생성한다.
   - 이러한 방법 및 기타 구조화된 SSM은 일반적으로 비선택적이고 일반적으로 엄격하게 선형 시간 불변(LTI)이었다.

3. **SSM을 사용하는 게이트 신경망 아키텍처**:
   - GSS는 게이티드 어텐션 유닛(GAU)에 의해 동기화된 SSM을 통합한 최초의 게이티드 신경망 아키텍처였다.
   - 메가는 효율적인 주의 근사를 사용하여 S4의 EMA 단순화를 하이브리드 아키텍처로 결합했다.

4. **선택적 S4 및 관련 모델**:
   - 선택적 S4는 선택 메커니즘보다 아키텍처 게이팅에 더 많이 고려되는 입력에 적용되는 이진 마스크를 생성한다.
   - Linear Attention 기반의 RetNet은 H3와 유사하지만 내부 S4 계층을 수정합니다.

5. **이전 RNN과 비교**:
   - 강력하게 유형화된 RNN, 준 RNN 및 단순 반복 단위와 같은 오래된 RNN은 시간적 비선형성 없이 게이트된 RNN 형태를 포함한다.
   - 이러한 오래된 RNN은 선택적 SSM의 경우로 볼 수 있지만 상태 확장 및 선택적 매개변수가 부족했다.
   - 그들은 또한 효율성 문제와 현대 구조화된 SSM이 더 나은 매개변수화와 고전적인 SSM 이론을 통해 해결하는 사라지는 그래디언트 문제로 고통을 받았다.

# 6 Conclusion

- 구조화된 상태 공간 모델에 선택 메커니즘을 도입하여 시퀀스 길이에서 선형 확장성을 유지하면서 컨텍스트 의존적 추론을 수행할 수 있도록 한다.
- 이 메커니즘을 무주의 모델인 맘바 아키텍처에 통합하면 다양한 영역에서 최첨단 결과를 얻을 수 있다.
- 맘바의 성능은 이들 영역에서 강력한 트랜스포머 모델과 맞먹거나 심지어 능가한다.
- 다양한 도메인, 특히 유전체학, 오디오 및 비디오와 같은 긴 컨텍스트를 필요로 하는 도메인에 대한 기본 모델을 구축하는 데 선택적 상태 공간 모델을 광범위하게 적용할 수 있는 잠재력.
- 맘바는 입증된 능력으로 인해 일반적인 서열 모델 백본의 유력한 후보로 제시되고 있다.


