---
layout: post
title:  "[PAPER] Confident Learning: Estimating Uncertainty in Dataset Labels"
author: jaealways
categories: [ paper, Data Science]
tags: [PAPER, JAIR'21, prompt]
---


# [PAPER] Confident Learning: Estimating Uncertainty in Dataset Labels

[reference: Curtis G. Northcutt et al, "Confident Learning: Estimating Uncertainty in Dataset Labels", 2021](https://arxiv.org/pdf/1911.00068.pdf)

# Abstract

- **자신감 학습(CL) Focus**: CL은 모델 예측이 아닌 데이터 세트의 레이블 품질을 강조하는 데이터 중심 접근 방식을 채택한다. 레이블 오류를 특성화하고 식별하는 것을 목표로 한다.

- **원리 및 방법**: 이 접근법은 잡음이 많은 데이터를 가지치기하고, 잡음을 추정하기 위해 확률적 임계값을 사용하여 계산하며, 자신감 있게 훈련하기 위해 예제의 순위를 매기는 것을 기반으로 한다. 이 원리들은 종종 다른 연구에서 독립적으로 개발된 것들과 결합된다.

- **클래스 조건부 노이즈 프로세스 및 조인트 분포 추정**: CL은 노이즈가 많은(주어진) 레이블과 손상되지 않은(알 수 없는) 레이블 간의 조인트 분포를 추정하기 위해 클래스 조건부 노이즈 프로세스를 가정하여 구축된다. 이 방법은 일관되고 성능이 뛰어난 일반화된 CL을 생성한다.

- **효과성 및 범용성**: 이 논문은 CL이 CIFAR 데이터 세트에서 노이즈가 많은 레이블로 학습하는 7가지 최근 방법을 능가하는 레이블 오류를 정확하게 찾는 것을 보여준다. 특히 CL은 특정 데이터 양식이나 모델에 국한되지 않는다. 예를 들어, MNIST 데이터 세트의 레이블 오류를 식별하고 Amazon Reviews에서 감정 분류를 개선하는 데 사용되었다.

- **ImageNet에 대한 적용 및 모델 정확도 향상**: CL은 라벨이 잘못 부착된 이미지를 식별하는 것과 같은 존재론적 클래스 중복을 정량화하기 위해 이미지넷 데이터 세트에 적용되었다. 또한 훈련 전 데이터를 클리닝하여 모델 정확도(예: ResNet의 경우)를 적당히 높이는 것으로 나타났다.

- **reproducability and Availability**: open-source cleanlab framework를 사용하여 결과와 방법을 복제할 수 있습니다.



# 1. Introduction


- **노이즈 라벨을 사용한 학습의 어려움**: 소개에서는 ImageNet, MS-COCO와 같은 대규모 데이터 세트와 건강 기록 및 교육과 같은 인간 중심 분야와 관련된 데이터 세트에서 노이즈 라벨이 일반적으로 발생한다는 점을 강조한다. 다양한 데이터 양식 및 모델에 걸쳐 라벨 오류가 있는 데이터를 식별하고 이를 통해 학습하는 방법에 대해 질문한다.

- **자신감 있는 학습의 개념(CL)**: 이 논문은 데이터 세트 레이블의 불확실성을 해결하기 위한 수단으로 '자신감 있는 학습' 개념을 소개한다. 이 접근 방식은 레이블 노이즈의 클래스 조건 특성에 초점을 맞추고 노이즈가 많은(주어진) 레이블과 실제(알 수 없는) 레이블 간의 공동 분포를 직접 추정하는 것을 목표로 한다.

- **CL**의 세 가지 주요 접근 방식: CL은 레이블 노이즈를 처리하기 위해 세 가지 원칙적인 접근 방식을 사용한다: (a) 반복적인 재라벨링의 함정을 피하면서 레이블 오류를 검색하는 가지치기, (b) 깨끗한 데이터에 집중하고 모델 가중치에서 오류 전파를 피하기 위한 카운트, (c) 견고성 발견 및 커리큘럼 학습 개념을 기반으로 교육 중에 사용할 순위 지정 예제.

- **공동 분포 추정과 그 중요성**: 공동 분포를 추정하는 것은 CL의 중심이다. 이 과정은 인식적 불확실성(모델 예측 확률)과 완화적 불확실성(소음 레이블)을 구별하는 것을 포함한다. 공동 분포는 잠재적 잡음 전이율, 손상되지 않은 레이블의 잠재적 이전 및 역잡음 비율과 같은 귀중한 통찰력을 제공한다.

- **모델-불가지론적 프레임워크 및 주요 기여**: CL은 레이블 오류를 식별하고 학습하기 위한 이론과 알고리즘으로 구성된 모델-불가지론적 프레임워크로 설명된다. 이 논문은 CL이 레이블 오류를 정확하게 식별하고 공동 분포를 추정하는 조건을 제공하는 증명과 레이블 노이즈 추정, 레이블 오류 찾기 및 노이즈 레이블과의 학습과 같은 작업에서 CL의 성능을 입증하는 경험적 데이터의 두 가지 주요 기여를 제시한다. 여기에는 Clean-ImageNet에서 ResNet 정확도를 높이고 CIFAR 데이터 세트에서 다른 방법을 능가하는 성능이 포함된다.

- **재현성 및 오픈 소스 가용성**: 이 논문은 결과와 방법론이 복제 가능하며 CL 알고리즘이 오픈 소스 Python 패키지인 cleanlab로 제공되었음을 강조한다.



# 2. CL Framework and Problem Set-up

### CL 프레임워크 및 문제 설정

- **상황 및 데이터 설명**:
  - CL은 잠재적으로 잡음이 많은 레이블이 있는 다중 클래스 데이터를 다룬다.
  - 데이터는 $\(X = (x, \tilde{y})^n\)$로 표시되며, 여기서 $\(\tilde{y}\)$는 \(m\) 고유 클래스 레이블이 있는 데이터 세트에서 \(n\) 예에 대해 관찰된 노이즈 레이블을 나타낸다.

- **가정**:
  - 모든 예제는 잠재적인 참 레이블 \(y^*\)을 가진다.
  - 클래스 조건부 분류 잡음 과정이 가정되는데, 클래스 \(j\)의 각 레이블은 특정 확률로 클래스 \(i\)로 잘못 레이블링 될 수 있다. 이 과정은 데이터 독립적인 것으로 간주된다.

- **주요 정의**:
  - **희소성**: 행렬 \(Q_{y^*}\)의 빗변형에서 0의 비율을 분석하여 데이터 세트의 레이블 노이즈의 불균일성을 측정한다. 희소성은 레이블 노이즈 특성을 이해하는 데 도움이 된다.
  - **자기 확신**: 어떤 예제가 주어진 레이블에 속할 확률을 예측한 것으로 정의한다. 레이블 오류 가능성에 대한 휴리스틱 지표로 사용된다.

- **CL 방법론**:
  - CL은 관측된 잡음 레이블과 참 잠재 레이블 간의 합동 분포를 추정하는 것을 목표로 한다.
  - 두 가지 입력이 필요합니다: 표본 외 예측 확률과 잡음 레이블의 벡터. 이 방법은 모델 매개변수 \( \theta \)와 관련된 특정 손실 함수에 무관합니다.
  - 이 접근법은 모델 교육과 데이터 청소를 분리하여 모델 선택의 유연성을 허용한다.

- ** 견적 프로세스**:
  - 관절 분포 \(Q_{\tilde{y}y^*}\)는 자신 있는 관절 \(C_{\tilde{y}y^*}\)을 사용하여 추정된다. 이 추정 과정은 분자와 분모를 보정하여 관측된 한계와 일치시키고 분포 합을 1로 보장하는 것을 포함한다.

- **데이터 정리 접근 방식**:
  - 추정 후 다양한 순위 및 프루닝 방법을 클린 데이터에 적용할 수 있다. 이러한 방법들은 잡음 추정과 훈련 손실을 결합하는 전통적인 방법에 비해 해석 가능성과 설명 가능성이 높다.
  - 이 논문은 이론적 조건과 실험 성능과의 일치로 인해 기본 선택은 \(C_{\tilde{y}y^*}\)이다.



# 3. CL Methods 


### CL 메소드

1. ** 라벨 소음 특성화**:
   - 관측된 선행 \(Q_{\tilde{y}=i} \) 및 \(Q_{y^*} \)의 주변을 활용하여 잠재 선행을 추정한다.
   - 이 방법은 데이터셋의 레이블 노이즈를 이해하고 특성화하기 위한 기초를 형성한다.

2. ** 카운트의 혼동 행렬(기준 방법)**:
   - 모든 예 \( x_k \)에 대해 \( |y_k = i, y_k^* = j | \) 카운트의 혼동 행렬을 구성한다.
   - 이 기본 접근법은 잡음 레이블로부터 훈련된 모델 예측이 실제 레이블을 밝혀낼 수 있다고 가정한다.
   - 무소음 예측 확률에 대한 일관된 추정량이지만 클래스 불균형이나 클래스별 확률 분포가 상이한 경우에는 한계가 있다.

3. **클래스별 임계값이 있는 신뢰할 수 있는 조인트 \(C_{yy^*} \)**:
   - 기준 방법의 한계, 특히 클래스-불균형 및 분포 이질성에 대한 민감도를 해결하기 위해 자신 있는 관절 \(C_{y^*} \)은 클래스별 임계값을 통합한다.
   - 이 방법은 교정의 형태를 제공하며 혼동 행렬 접근법보다 더 강건한 것으로 나타난다.

4. **랭킹 및 프룬: 데이터 정리**:
   - \( C_{yy^*} \) 및 \( Q_{y^*} \)를 추정한 후, 데이터 클리닝을 위해 임의의 랭크 및 프룬 접근법을 사용할 수 있다.
   - CL의 이러한 모듈화는 해석 가능하고 설명 가능한 순위 결정 방법을 사용하여 레이블 오류를 식별할 수 있게 하며, 이는 일반적으로 훈련 손실과 노이즈 추정을 결합했던 이전 방법에 비해 개선된 것이다.

이 방법들은 라벨 노이즈를 특성화하고, 참 라벨을 추정하고, 데이터를 청소하기 위해 자신감 있는 학습에서 사용되는 핵심 방법론을 강조한다. 이 방법은 라벨의 클래스 불균형 및 노이즈와 같은 다양한 문제를 처리하는 데 있어 유연성과 견고성을 강조한다.



# 4. Theory

"자신감 학습: 데이터셋 라벨의 불확실성 추정" 논문의 "이론" 부분은 다음과 같이 요약할 수 있다:

### 이론

1. ** 라벨 오류 추정 방법**:
   - \( C_{yy^*} \)의 오프 diagonals를 사용하여 \( \hat{X}_{\tilde{y}=i, y^*=j} \)를 추정합니다. 즉, 오프 diagonals에 계산된 예제 세트를 직접 사용하여 레이블 오류를 추정합니다.
   - 두 가지 방법이 개략적으로 제시되어 있다:
     - **CL baseline 1(C 혼동)**: 레이블 오류를 부울 벡터로 추정하며, true는 레이블 오류를 의미하고 false는 clean data를 의미합니다.
     - **CL method 2 (Cyy ˜ ∗)**: 접근 방식을 사용하여 레이블 오류를 추정합니다. \( \hat{X}_{\tilde{y}=i, y^*=j} : i \neq j\} \).

2. **추정기법**:
   - 이 방법은 \( n \cdot \hat{Q}_{y^*} \)을 계산하여 \( |\hat{X}_{\tilde{y}=i, y^*=j}| \)를 추정한 다음 확률 순위에 의해 프루닝한다.
   - 두 가지 접근법이 고려된다:
     - ** 클래스별 프루닝(PBC)**: 각 클래스 \(i\)에 대해 프루닝할 상위 \(n \cdot \hat{Q}_{yy^*}[i]\) 예제를 선택합니다.
     - **노이즈 레이트에 의한 프루닝(PBNR)**: \( \hat{Q}_{\tilde{y}=i, y^*=j} \)의 각 오프 diagonal 항목에 대해, \(i \neq j\) 프루닝을 위한 각각의 예를 선택한다.

3. **프루닝 방법 조합**:
   - **CL method 5 (C+NR)**: 요소별 'and' 연산을 사용하여 앞의 두 가지 방법(PBC 및 PBNR)을 결합하는데, 두 가지 방법이 모두 프루닝을 제안하는 경우 예를 프루닝한다는 것을 의미한다.

4. **노이즈 라벨을 사용한 학습**:
   - 오류가 제거된 훈련을 위해 잘못된 레이블 제거로 인한 데이터 누락을 설명하는 각 클래스 \(i\)에 대해 손실의 가중치를 \(1/\hat{Q}_{y^*}[i][i] \)로 재조정한다.

이 요약은 노이즈가 많은 레이블이 있는 데이터 세트의 레이블 오류를 추정하고 처리하기 위한 자신감 학습 프레임워크에서 사용되는 이론적 접근 방식과 방법을 요약한다. 잘못된 레이블을 식별하고 정리하는 전략과 정리된 데이터로 훈련 모델에서 그에 따른 조정을 강조한다.


# 5. Experiments

"자신감 학습: 데이터셋 라벨의 불확실성 추정" 논문의 "실험" 부분은 다음과 같이 요약할 수 있다:

### 실험

1. **CL Method의 선택**:
   - 데이터 클리닝을 위한 5가지 방법 중 CL: \( C_{y^*} \)은 정리 2의 조건을 준수하고 실험 성능을 높이기 위해 기본적으로 선택된다. 이 방법은 레이블 오류를 정규화된 마진으로 효과적으로 식별하고 정렬한다.

2. **이론적 조건에서의 근사**:
   - 실제 값 \(Q_{y^*} \)을 추정하기 위해 이산 카운트 기반 \(C_{y^*} \)을 사용하는 정밀도 오차를 나타내는 근사치로 표기 \( \hat{Q}_{y^*} \)를 사용한다. 이 근사치는 해당 클래스의 몇 가지 예만 있는 데이터 세트에서 0.39의 노이즈 속도와 같은 상황을 설명하는 데 필요하다.

3. **임계값에 대한 이상적인 조건**:
   - 이 논문에서는 예측 확률 \( \hat{p}(y_{\tilde{y}=i}; x, \theta) \)이 이상적일 때 임계값 \( t_i \)에 대한 닫힌 형식 표현을 제공하는 보조정리에 대해 논의합니다. 이 보조정리는 레이블 노이즈와 모델 노이즈를 구별하는 데 중요합니다.

4. **예측 확률 및 소음 비율**:
   - 예측된 확률과 실제 소음율 간의 관계를 탐구한다. 본 논문에서는 예측된 확률이 다양한 조건과 다양한 클래스에서 실제 소음율과 어떻게 일치하는지 살펴본다.

5. **이상적인 임계값 보조정리**:
   - 실험은 잡음이 많은 데이터 집합에 대한 "이상적인 임계값" 보조정리에 기초한 분석을 포함한다. 이 보조정리는 잡음이 많은 데이터의 맥락에서 올바른 임계값을 이해하고 적용하는 데 기본적이다.

요약은 다양한 CL 방법의 선택과 성능, 이러한 방법의 이론적 토대, 이러한 방법을 라벨 노이즈가 있는 실제 데이터 세트에 적용하는 데 필요한 실제 고려 사항에 초점을 맞추어 실험 섹션의 주요 측면을 포착한다.


# 6. Related work

"자신감 학습: 데이터셋 레이블의 불확실성 추정" 논문의 "관련 작업" 부분은 다음과 같이 요약할 수 있다:

### 관련 작업

1. **임계값 공식 및 직관**:
   - 임계값 공식은 올바른 레이블링과 잘못된 레이블링의 확률을 고려합니다. 이상적인 조건에서 보조정리 1을 사용하여 자신감 있는 학습(CL)이 레이블 오류를 정확하게 찾고 \( \hat{Q}_{y^*} \)의 대각선 항목이 \(Q_{\tilde{y}|y^*} \)의 행과 열을 최대화하여 충돌을 제거할 때 \(Q_{y^*} \)에 대한 일관된 추정치임을 증명합니다.

2. **예측 확률의 이상적인 조건**:
   - 이상적인 조건에서, \(Q_{\tilde{y}|y^*} \)의 각 대각선 항목은 행과 열을 최대화하고, 모델 \( \theta \)은 \(x \)를 \hat{p}(\tilde{y}; x, \theta) \) 완벽하게, 추정된 집합 \( \hat{X}_{\tilde{y}=i,y^*=j} \)은 실제 집합 \(X_{\tilde{y}=i,y^*=j} \)과 일치한다.

3. ** 이론 1과 혼동에 대한 적용**:
   - 정리 1은 \(Q_{\tilde{y}|y^*} \)의 대각선이 행과 열을 최대화할 경우, \(C_{confusion} \)가 사용하는 접근 방식이 정리의 조건을 만족한다는 것을 보여주는 건전성 검사 역할을 한다. 이는 잡음과 참 레이블의 공동 분포를 일관성 있게 추정할 수 있는 방법의 능력을 강조한다.

4. ** 클래스 불균형 및 이종 클래스 확률 분포 해결**:
   - 이 논문은 잡음이 많은 예측 확률의 맥락에서 클래스 불균형과 이질적 클래스 확률 분포를 다루는 것의 중요성을 강조한다.

5. **클래스별 회절 조건**:
   - \( \hat{p}(x_{\tilde{y}=j}) \) 예측 확률이 클래스 조건부 오류의 선형 조합에 걸쳐 확산되어 클래스 간에 보다 균형 잡힌 표현을 보장하는 "클래스별 회절" 조건을 도입한다.

이 요약은 라벨 노이즈 특성화 및 보정 분야의 기존 방법론 및 과제와 관련하여 자신감 학습(Confident Learning)의 이론적 기반과 실무적 고려 사항을 강조한다. 데이터 세트의 라벨 오류를 식별하고 보정하는 과정에서 정확한 확률 추정, 클래스 균형 및 오류 분포의 중요성을 강조한다.


# 7. Conclusion and Future Work


1. **클래스별 견고성 상관 관계**:
   - 잡음이 많은 데이터 세트와 모델에 대한 클래스별 견고성을 주장하는 Corollary 1.1을 소개합니다. 여기서 예측된 확률 \( \hat{p}(x_{\tilde{y}=j}) \)은 레이블 충돌 없이 클래스별로 회절됩니다. 이 측면은 클래스 조건부 과신으로 알려진 신경망에 매우 중요합니다.

2. **일관성 추정**:
   - 이 접근 방식은 \( \hat{Q}_{y^*} \)이 \(Q_{y^*} \)에 대한 일관된 추정기임을 보장하여 레이블 노이즈가 있는 데이터 세트에서 정확한 예측 및 오류 추정을 가능하게 한다.

3. **클래스별 오류에 대한 견고성**:
   - 이 방법은 확률에서 클래스당 오류의 선형 조합에 대해 강력한 것으로 나타난다. 클래스 분포 및 오류가 매우 가변적일 수 있는 실제 시나리오에서 신뢰성을 보장하기 때문에 이러한 견고성은 매우 중요하다.

4. **C 혼란의 한계**:
   - 이 논문은 특히 클래스 불균형이나 분포 이동을 처리하는 데 효과적이지 않을 수 있는 극단적인 클래스 회절의 경우 C 혼란 방법의 한계를 강조한다.

5. **Cyy ˜ ∗의 장점**:
   - 이에 비해 Cyyy ˜ ∗은 행렬의 열을 다시 정규화하고 분포 이동 및 계층 불균형에 강건하게 대처함으로써 이러한 한계를 극복하는 데 효과적임을 보여준다. 이 방법은 확률과 오차가 매우 다양할 수 있는 실제 상황에 더 잘 적응한다.

6. **예제별 회절 조건**:
   - 예측 확률이 예별로 조정되는 예별 회절 조건을 소개하여 데이터 세트의 다양하고 복잡한 오류 패턴을 처리할 수 있는 모델의 용량을 더욱 향상시킨다.

결론은 잡음이 많은 데이터 세트에서 클래스 불균형, 분포 이동 및 가변 오류 패턴을 처리하는 데 있어 자신감 있는 학습의 견고성과 적응성을 강조한다. 또한 특정 방법의 한계와 실제 데이터의 복잡성을 해결하기 위한 접근 방식의 지속적인 적응 및 개선 필요성을 지적한다.

