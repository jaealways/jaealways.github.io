---
layout: post
title:  "[PAPER] What the DAAM: Interpreting Stable Diffusion Using Cross Attention"
author: jaealways
categories: [ paper, NLP]
tags: [PAPER, ACL'22, multi-modal]
---


# [PAPER] What the DAAM: Interpreting Stable Diffusion Using Cross Attention

[reference: Raphael Tang et al, "What the DAAM: Interpreting Stable Diffusion Using Cross Attention", 2023](https://arxiv.org/pdf/2210.04885.pdf)


# Abstract

- text-to-image 분야 모델의 해석가능성에 대한 분석이 부족하다는 점에서 대규모 확산 신경망을 이해하는 문제를 다룸
- Diffusion Attentic Attribution Maps, DAAM이라는 방법을 도입하여 오픈 소스 모델인 Stable Diffusion 모델에 대한 텍스트-이미지 속성 분석을 수행
- DAAM은 pixel-level attribution 맵을 만들기 위해 잡음 제거 서브네트워크 내에서 교차 주의 워드-픽셀 스코어를 업스케일링하고 집계함
- DAAM의 의미 세분화 능력을 테스트하고 인간이 평가한 모든 음성 부분에 걸쳐 일반적인 속성 품질을 평가함으로써 DAAM의 정확성을 평가
- DAAM을 사용하여 픽셀 공간에서 syntax의 역할을 탐구하고, 특히 10개의 공통 의존 관계에 대한 head-dependent heatmap에서의 상호 작용 패턴을 조사
- DAAM을 사용하여 특징 얽힘을 중심으로 몇 가지 의미 현상을 조사한다. 
  - 코히포니즘(공유된 하이퍼님이 있는 단어)은 생성 품질에 부정적인 영향을 미침
  - 서술형 형용사는 생성된 이미지에서 주의 집중 시간이 너무 넓은 경향이 있음
- 대형 확산 모델을 시각언어학적 관점에서 최초로 해석


# 1 Introduction

- 이미지 분할 방법인 DAAM을 정량적으로 평가하고자 함. 
  - 기존 데이터셋과 방법을 활용하여 DAAM이 의미론적으로 의미 있는 분할 레이블, 특히 명사를 중심으로 얼마나 잘 일치하는지 평가
- 이미지당 30개의 추론 단계를 가진 Stable Diffusion 2.0 기본 모델을 사용
  - 하나는 현실적인 프롬프트에 COCO 이미지 캡션 데이터 세트를 사용
  - 다른 하나는 비현실적인 프롬프트에 무작위로 명사를 교체 
  - 모델이 비정상적이거나 가능성이 없는 프롬프트로 일반화하는 능력을 테스트하는 것이 목적
- DAAM의 성능은 COCO(Mask R-CNN, QueryInst, Mask2Former 등)에서 훈련된 감독된 의미 분할 모델 및 STEGO 및 PiCIE + H와 같은 감독되지 않은 모델과 비교
- 사용된 평가 메트릭은 mIoU(mean intersection over union)

- DAAM은 mIoU ∞에서 COCO 감독 모델을 22~28점 능가하고 mIoU80에서 20점 정도 성능이 떨어짐
- 가장 성능이 좋은 모델인 개방형 어휘 모델인 CLIPeg는 mIoU80과 mIoU ∞ 모두에서 높은 성능
- DAAM은 비논리적인 텍스트에 대한 복원력을 입증하여 일반화 능력을 보여줌

- DAAM 진정성 분석을 명사를 넘어 형용사, 동사 등 모든 발화 부분으로 확장
- DAAM 지도의 속성 품질을 5점 리커트 척도로 평가하는 인간 평가자가 포함

- 2800개의 고유 단어-프롬프트 쌍이 생성되며, COCO에서 가장 일반적인 14개의 품사 태그를 포함
- 이 쌍에 대해 이미지와 DAAM 맵이 생성된다. 사람의 판단은 Amazon MTurk를 통해 수집

- 형용사, 동사, 명사, 고유명사의 DAAM 지도는 대부분 '좋음'에 가깝거나 그 이상의 평가를 받는 반면, 숫자와 부사의 지도는 '공정함'에 가까움
- DAAM이 해석 가능한 각 발화 부분에 대해 그럴듯한 지도를 생성한다고 결론지었지만, 히트맵이 다른 것이 동일한 단어를 설명할 수 있으므로 정성적 비교보다는 신뢰성을 입증하는 데 더 중점을 둔다고 지적


# 2 Our approach

## 2.1 Preliminaries
- **Latent Diffusion Models**: 임의의 잡음으로부터 고충실도 이미지를 생성하도록 훈련된 잡음 제거 생성 모델, 선택적으로 텍스트에 조건부, 크게 다음 세 개의 구성으로 이뤄짐
  - **Deep Language Model**: 단어 임베딩을 생성하는 데 사용되는 CLIP과 유사
  - **VAE(Variational Autoencoder)**: 영상의 잠재 벡터를 인코딩하고 디코딩
  - **시간-조건부 U-Net**: 잠재 벡터를 점진적으로 잡음 제거

- **이미지 생성 프로세스**: 랜덤 노이즈로 잠재 벡터를 초기화하고 텍스트 프롬프트에서 피드하며 U-Net을 사용하여 이러한 벡터를 반복적으로 노이즈 제거한 후 최종 벡터를 VAE로 이미지로 디코딩

- **트레이닝 및 최적화**: 네트워크는 캡션-이미지 쌍으로 훈련되어 점수 일치를 위해 하한의 증거에 대해 가중치가 부여된 형태를 최적화
  - 가우시안 노이즈로 초기화되고 노이즈 제거 프로세스를 통해 반복되는 잠재 벡터를 생성

## 2.2 Diffusion Attentive Attribution Maps
- 텍스트-이미지 합성을 위한 대규모 잠재 확산 모델에서 각 단어에 의해 이미지의 어떤 부분이 가장 큰 영향을 받는지 결정

- **Attention Mechanism**: 이미지의 좌표 인식 잠재 표현과 텍스트 임베딩을 교차 맥락화하는 주의 메커니즘을 활용 
- **정규화 및 해석**: [0, 1]에서 정규화된 주의 점수는 각각의 단어를 이미지 패치와 연관시키는 것으로 해석
- **공간적 집계**: 공간적 차원에 대해 정규화된 주의 점수를 집계하고 이미지 전체에 걸쳐 보간
- **U-Net 및 Cross-Attention Layer**: 단어 임베딩에 대한 이러한 표현을 조건화하기 위해 다중 헤드 교차 주의 계층이 있는 U-Net의 다운 샘플링 및 업 샘플링 블록을 사용
- **Heat Maps Creation**: 어텐션 스코어 배열을 원래 이미지 크기로 업스케일링하고 헤드, 레이어, 타임 스텝에 걸쳐 합산하여 Heat Maps를 생성. 
  - Heat Maps는 임계값을 기준으로 소프트 또는 하드 바이너리 맵으로 시각화

- **일러스트**: 멀티스케일 어텐션 어레이, 바이큐빅 보간 및 문턱값을 포함하는 주어진 단어에 대한 DAAM을 계산하는 단계를 나타내는 일러스트를 사용


# 3 Attribution Analyses

## 3.1 Object Attribution
- DAAM 방법이 의미론적으로 의미 있는 이미지 분할 레이블과 일치하는 데 있어서 명사를 중심으로 그 효과를 평가
### Setup
- **Experiment Setup**: 안정 확산 2.0 모델을 활용하여 COCO 이미지 캡션 데이터 세트의 현실적인 프롬프트와 일반화를 테스트하기 위해 무작위로 스왑된 명사가 있는 또 다른 세트의 두 가지 프롬프트에서 이미지를 생성
- **Ground Truth 비교**: 생성된 이미지를 Ground Truth 이미지에 존재하는 손으로 분할된 명사와 비교
- **DAAM 분할 마스크**: 이진 DAAM 분할 마스크는 각 명사에 대해 다양한 임계값을 사용하여 계산
- **감독된 기준선과 감독되지 않은 기준선과의 비교**: DAAM은 여러 의미 분할 모델과 감독되지 않은 기준선에 대해 평균 교차점(mIoU)을 메트릭으로 사용하여 평가
### Results
- **Results**: DAAM은 개방형 어휘 시나리오와 감독되지 않은 기준선에서 감독 모델을 능가하며, 비상식적인 텍스트에 대한 복원력과 구성 일반화의 효과를 보여줌

## 3.2  Generalized Attribution
### Setup
- **목적**: 명사를 넘어 형용사, 동사 등 모든 품사로 분석을 확장
- **인간 주석 요구 사항**: 일반적으로 단어는 효과적인 분할 주석을 위해 시각적으로 분리할 수 없기 때문에 5점 리커트 척도를 사용하여 DAAM 맵의 속성 품질을 평가하는 인간 평가자를 포함
- **실험 절차**: COCO에서 14개의 공통 품사 태그를 포함하는 2800개의 고유 워드-프롬프트 쌍으로 단어-이미지 데이터 세트를 구성
  - 모든 쌍에 대한 DAAM 맵과 함께 이미지를 생성하고 Amazon MTurk를 통해 인간의 판단을 수집
### Results
- 조사 결과에 따르면 형용사, 동사, 명사 및 고유명사에 대한 DAAM 지도는 일반적으로 "좋음"에 가깝거나 그 이상의 평가를 받으며, 숫자 및 부사는 "공정"에 가까움 
- 전반적으로 DAAM은 해석 가능한 각 발화 부분에 대해 그럴듯한 지도를 만듦


# 4 Visuosyntactic Analysis

- DAAM을 사용하여 생성된 픽셀과 구문이 어떻게 관련되는지 조사

### Setup
- 머리에 의존하는 DAAM 맵 간의 쌍방향 상호작용의 특성화, COCO에서 1000개의 프롬프트를 분석하고 모든 단어에 대한 DAAM 맵을 생성
- 조합 위의 평균 시각 교차 영역(mIoU), 종속 교차 영역(mIoD), 머리 위 교차 영역(mIoH)과 같은 집합 기반 유사성 통계를 사용하여 상위 10개의 가장 일반적인 구문 관계에 초점

### Results
- **기준 비교**: 관련이 없는 단어 쌍과 머리 의존적인 모든 쌍에서 중간 정도의 유사성과 우성이 관찰되지 않았음
- **구문 관계 분석**:
  - 명사 화합물(예: "아이스크림")에서는 지배력이 없다.
  - 구두점 및 기사(예: "punct" 및 "det")는 이미지 전반에 걸친 광범위한 주의로 인해 지배력을 나타내지 않는다.
  - 시각적 분리(예: "cat and dog")로 인해 "and"와 연결된 명사에서 중복이 적다.
- **지도의 지배**:
  - 핵심 논변(nsubj, obj)에서는 머리말이 우세하다.
  - 명목 종속어(nmod:of, amod, acl)에서, 집합 명사는 직관적인 우세를 보이는 반면, 형용사는 놀랍게도 그들이 수식하는 명사를 지배한다.
  - 핵심 서로 다른 단어 쌍이 가장 높은 중첩을 보여 동일한 참조에 대한 주의를 나타낸다.


# 5 Visuosemantic Analyses

## 5.1 Cohyponym Entanglement
- **목적**: 프롬프트에서 의미론적으로 유사한 단어(코히포니움)가 생성된 이미지의 품질에 미치는 영향을 조사
- **방법론**: WordNet을 활용하여 COCO의 시각적 객체 위에 의미론적 필드를 표현하는 온톨로지를 만듦
  - 두 개의 서로 다른 객체를 가진 프롬프트를 사용하여 이미지를 생성했으며 때로는 코히포니움으로, 때로는 그렇지 않았음
- **주석 프로세스**: 이미지는 존재하는 개체를 식별하는 주석자에 의해 평가되었음
  - 프롬프트에서 두 단어가 모두 존재하는 경우 이미지가 올바른 것으로 간주
- **Results**: 비협조어를 사용한 프롬프트는 코히포니즈(52%)에 비해 생성 정확도(61%)가 더 높은 것으로 나타남
  - 이는 코히포니즈가 DAAM 맵에서 중첩을 증가시켜 얽힌 주의력과 구성을 나타냄을 시사

## 5.2 Adjectival Entanglement
- **목적**: 명사의 수식 형용사가 전체 이미지에 어떤 영향을 미치는지 연구
- **방법론**: 다양한 형용사를 가진 프롬프트에서 생성된 이미지를 분석
  - 형용사가 변형되었을 때 특히 배경에서 이미지의 변화를 관찰하는 데 초점
- **사례 연구**:
  - **a {rusty, metallic, wooden} shovel sitting in a clean shed**: 형용사(예: "녹슨", "금속", "나무")를 바꾸면 그에 상응하는 창가의 외관에 변화
  - **a {bumpy, smooth, spiky} ball rolling down a hill**: "bumpy", "smooth", "spicky"와 같은 형용사들이 땅의 모양에 영향
  - **a {blue, green, red} car driving down the streets**: 색 형용사("파란색", "녹색", "빨간색")가 배경의 색에 영향
- **관찰**: 실험을 통해 형용사가 수정하려는 대상뿐만 아니라 이미지 전체에 광범위하게 영향을 미침
- 이미지 생성 과정에서 형용사 얽힘의 한 형태


# 6 Related Work and Future Directions

- **컴퓨터 언어학과 신경망**: 텍스트 섭동, 주의 시각화 및 정보 병목 현상을 대규모 언어 모델에 적용한 이전 연구와 일치한다.

- **확산 모델에서의 시각언어적 현상**: 본 논문은 확산 모델에서 단어-픽셀 교차 주의 지도를 탐색하고, 의미 분할 작업과 정성적 속성 연구를 통해 DAAM 방법의 정확성을 확립
  - 구문 관계가 시각적 상호작용으로 어떻게 변환되는지 살펴보고, 코히포니가 뒤섞이고 형용사가 지나치게 광범위한 영향을 미치는 등의 특징 얽힘 문제를 밝혀냄

- **앞으로의 연구 방향**:
  - **비감독 파싱 능력**: 구문-기하학 프로브를 사용하여 Stable Diffusion의 비감독 파싱 능력을 평가할 계획
  - **텍스트-이미지 생성과의 교차점**: 텍스트-이미지 생성과 NLP의 교차점은 상당하며, 신속한 엔지니어링을 통해 확산 모델의 잠재적인 향상
  - **특징의 분리**: 미래의 작업 라인은 생성 품질을 향상시키기 위해 확산 모델에서 얽힌 개념을 분리하는 것을 포함
  - **시맨틱 세그멘테이션**: 안정 확산(Stable Diffusion)에서 DAAM의 강력한 기준선 수와 귀중한 잠재 표현을 활용하여 시맨틱 세그멘테이션 파이프라인에 DAAM을 사용할 가능성


# 7 Conclusions

- 신경망이 언어적 정보를 처리하는 방법을 탐구함으로써 향후 연구에 대한 정보를 제공하는 것을 목표
- **확산모델에서의 시각언어적 현상에 관한 연구**: 확산모델에서의 단어-픽셀 교차주의 지도 해석에 초점을 맞춘 연구
  - 정량적 의미 세분화 작업과 정성적 속성 연구를 통해 DAAM 방법을 검증

- **구문 관계 및 특징 얽힘에 대한 연구 결과**: 구문 관계가 이미지 생성에서 시각적 상호 작용으로 어떻게 변환되는지에 대한 통찰력을 제공
  - 생성된 이미지에서 의미론적으로 관련된 단어(동음이)가 뒤섞이는 특징 얽힘 및 지나치게 광범위한 영향을 미치는 형용사와 같은 문제를 식별
- **미래 연구 및 언어 분석 기여**: 텍스트-이미지 합성 모델을 이해하고 개선하는 데 있어 향후 연구를 위한 토대를 마련
  - 확산 모델에서의 감독되지 않은 파싱 능력, 텍스트-이미지 생성과 자연어 처리의 교차와 같은 분야에서 추가적인 탐색의 필요성을 강조
